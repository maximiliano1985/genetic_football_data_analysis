{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Goal here (pun intended) is to design a prediction system which can accurately predict if the home team will win or not. We will use the final dataset got by our earlier \"Scraping and Cleaning\" Notebook build our prediction model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from time import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR',\n",
      "       'HTGS', 'ATGS', 'HTGC', 'ATGC', 'HTP', 'ATP', 'HM1', 'HM2', 'HM3',\n",
      "       'HM4', 'AM1', 'AM2', 'AM3', 'AM4', 'B365H', 'BWH', 'IWH', 'LBH', 'WHH',\n",
      "       'B365D', 'BWD', 'IWD', 'LBD', 'WHD', 'B365A', 'BWA', 'IWA', 'LBA',\n",
      "       'WHA', 'HomeTeamLP', 'AwayTeamLP', 'MW', 'ENTROPY_B365', 'ENTROPY_BW',\n",
      "       'ENTROPY_IW', 'ENTROPY_LB', 'ENTROPY_WH', 'ENTROPY_H', 'ENTROPY_D',\n",
      "       'ENTROPY_A', 'HTFormPtsStr', 'ATFormPtsStr', 'HTFormPts', 'ATFormPts',\n",
      "       'HTWinStreak3', 'HTWinStreak5', 'HTLossStreak3', 'HTLossStreak5',\n",
      "       'ATWinStreak3', 'ATWinStreak5', 'ATLossStreak3', 'ATLossStreak5',\n",
      "       'HTGD', 'ATGD', 'DiffPts', 'DiffFormPts', 'DiffLP'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read data and drop redundant column.\n",
    "#data = pd.read_csv('../Datasets/final_dataset_complete.csv')\n",
    "data = pd.read_csv('../Datasets/serie_A/final_dataset_serieA.csv')\n",
    "\n",
    "N_MATCHES_TO_PREDICT = 20\n",
    "\n",
    "OPTIMIZE_HYPERPARAMETERS = False\n",
    "\n",
    "out_classifierFilename = 'football_classifier_serieA_bis.pkl'\n",
    "\n",
    "\n",
    "# Remove first 3 matchweeks\n",
    "data = data[data.MW > 3]\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualising distribution of data\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "data_training = data.iloc[:-N_MATCHES_TO_PREDICT, :]\n",
    "\n",
    "\n",
    "## bis\n",
    "#scatter_matrix(data[['HTGD','ATGD','HTP','ATP','DiffFormPts','DiffLP']], figsize=(10,10));\n",
    "\n",
    "## tris\n",
    "#scatter_matrix(data_training[['HTGD','ATGD','HTP','ATP','DiffFormPts','DiffLP','HTFormPts', 'ATFormPts','HTGS', 'ATGS', 'HTGC', 'ATGC', 'ENTROPY_B365', 'ENTROPY_H', 'ENTROPY_A', 'HomeTeamLP', 'AwayTeamLP']], figsize=(10,10));\n",
    "#scatter_matrix(dd[['ENTROPY_B365', 'ENTROPY_BW', 'ENTROPY_IW', 'ENTROPY_LB', 'ENTROPY_WH', 'ENTROPY_H', 'ENTROPY_D', 'ENTROPY_A']], figsize=(10,10));\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FTR', 'HTP', 'ATP', 'HM1', 'HM2', 'HM3', 'AM1', 'AM2', 'AM3', 'HTGD',\n",
      "       'ATGD', 'DiffFormPts', 'DiffLP'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#data.drop(['Unnamed: 0','HomeTeam', 'AwayTeam','Date', 'MW', 'HTFormPtsStr', 'ATFormPtsStr', 'FTHG', 'FTAG',\n",
    "#           'HTGS', 'ATGS', 'HTGC', 'ATGC','HomeTeamLP', 'AwayTeamLP','DiffPts','HTFormPts','ATFormPts',\n",
    "#           'HM4','HM5','AM4','AM5','HTLossStreak5','ATLossStreak5','HTWinStreak5','ATWinStreak5',\n",
    "#           'HTWinStreak3','HTLossStreak3','ATWinStreak3','ATLossStreak3'],1, inplace=True)\n",
    "## bis\n",
    "data.drop(['Unnamed: 0','HomeTeam', 'AwayTeam','Date', 'MW', 'HTFormPtsStr', 'ATFormPtsStr', 'FTHG', 'FTAG',\n",
    "           'HTGS', 'ATGS', 'HTGC', 'ATGC','HomeTeamLP', 'AwayTeamLP','DiffPts','HTFormPts','ATFormPts',\n",
    "           'HM4','AM4','HTLossStreak5','ATLossStreak5','HTWinStreak5','ATWinStreak5',\n",
    "           'HTWinStreak3','HTLossStreak3','ATWinStreak3','ATLossStreak3', 'ENTROPY_B365', 'ENTROPY_BW',\n",
    "           'ENTROPY_IW', 'ENTROPY_LB', 'ENTROPY_WH', 'ENTROPY_H', 'ENTROPY_D', 'ENTROPY_A',\n",
    "           'B365H', 'BWH', 'IWH', 'LBH', 'WHH', 'B365D', 'BWD', 'IWD', 'LBD', 'WHD', 'B365A', 'BWA', 'IWA',\n",
    "            'LBA', 'WHA'],1, inplace=True)\n",
    "## tris\n",
    "#data.drop(['Unnamed: 0', 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG',\n",
    "#        'B365H', 'BWH', 'IWH', 'LBH', 'WHH', 'B365D', 'BWD', 'IWD', 'LBD', 'WHD', 'B365A', 'BWA', 'IWA', 'LBA',\n",
    "#        'WHA', 'MW','ENTROPY_BW', 'ENTROPY_IW', 'ENTROPY_LB', 'ENTROPY_WH', 'ENTROPY_D', 'HTFormPtsStr', 'ATFormPtsStr', 'HTWinStreak5',\n",
    "#        'HTLossStreak5', 'ATWinStreak5', 'ATLossStreak5'],1, inplace=True)\n",
    "\n",
    "# ,'HomeTeam', 'AwayTeam'\n",
    "# Preview data.\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of matches: 3889\n",
      "Number of features: 12\n",
      "Number of matches won by home team: 1812\n",
      "Win rate of home team: 46.59%\n"
     ]
    }
   ],
   "source": [
    "# Total number of students.\n",
    "n_matches = data.shape[0]\n",
    "\n",
    "# Calculate number of features.\n",
    "n_features = data.shape[1] - 1\n",
    "\n",
    "# Calculate matches won by home team.\n",
    "n_homewins = len(data[data.FTR == 'H'])\n",
    "\n",
    "# Calculate win rate for home team.\n",
    "win_rate = (float(n_homewins) / (n_matches)) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of matches: {}\".format(n_matches))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of matches won by home team: {}\".format(n_homewins))\n",
    "print(\"Win rate of home team: {:.2f}%\".format(win_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate into feature set and target variable\n",
    "X_all = data.drop(['FTR'],1)\n",
    "y_all = data['FTR']\n",
    "\n",
    "# Standardising the data.\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "## bis\n",
    "cols = [['HTGD','ATGD','HTP','ATP','DiffFormPts', 'DiffLP']]\n",
    "\n",
    "## tris\n",
    "#cols = ['HTGS', 'ATGS', 'HTGC', 'ATGC', 'HTP', 'ATP', 'HomeTeamLP', 'AwayTeamLP',\n",
    "#       'ENTROPY_B365', 'ENTROPY_H', 'ENTROPY_A',\n",
    "#       'HTFormPts', 'ATFormPts', 'HTWinStreak3', 'HTLossStreak3',\n",
    "#       'ATWinStreak3', 'ATLossStreak3', 'HTGD', 'ATGD', 'DiffPts',\n",
    "#       'DiffFormPts', 'DiffLP']\n",
    "for col in cols:\n",
    "    X_all[col] = scale(X_all[col])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (24 total features):\n",
      "['HTP', 'ATP', 'HM1_D', 'HM1_L', 'HM1_W', 'HM2_D', 'HM2_L', 'HM2_W', 'HM3_D', 'HM3_L', 'HM3_W', 'AM1_D', 'AM1_L', 'AM1_W', 'AM2_D', 'AM2_L', 'AM2_W', 'AM3_D', 'AM3_L', 'AM3_W', 'HTGD', 'ATGD', 'DiffFormPts', 'DiffLP']\n"
     ]
    }
   ],
   "source": [
    "X_all.HM1 = X_all.HM1.astype('str')\n",
    "X_all.HM2 = X_all.HM2.astype('str')\n",
    "X_all.HM3 = X_all.HM3.astype('str')\n",
    "X_all.AM1 = X_all.AM1.astype('str')\n",
    "X_all.AM2 = X_all.AM2.astype('str')\n",
    "X_all.AM3 = X_all.AM3.astype('str')\n",
    "\n",
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the football data and converts catagorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)\n",
    "                    \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print( \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HTP</th>\n",
       "      <th>ATP</th>\n",
       "      <th>HM1_D</th>\n",
       "      <th>HM1_L</th>\n",
       "      <th>HM1_W</th>\n",
       "      <th>HM2_D</th>\n",
       "      <th>HM2_L</th>\n",
       "      <th>HM2_W</th>\n",
       "      <th>HM3_D</th>\n",
       "      <th>HM3_L</th>\n",
       "      <th>...</th>\n",
       "      <th>AM2_D</th>\n",
       "      <th>AM2_L</th>\n",
       "      <th>AM2_W</th>\n",
       "      <th>AM3_D</th>\n",
       "      <th>AM3_L</th>\n",
       "      <th>AM3_W</th>\n",
       "      <th>HTGD</th>\n",
       "      <th>ATGD</th>\n",
       "      <th>DiffFormPts</th>\n",
       "      <th>DiffLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.558071</td>\n",
       "      <td>1.007151</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.388674</td>\n",
       "      <td>1.193709</td>\n",
       "      <td>-2.193275</td>\n",
       "      <td>0.525810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.558071</td>\n",
       "      <td>2.074186</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.388674</td>\n",
       "      <td>1.597666</td>\n",
       "      <td>-3.687346</td>\n",
       "      <td>0.314922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-2.152808</td>\n",
       "      <td>-1.660437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.195503</td>\n",
       "      <td>-0.422117</td>\n",
       "      <td>-0.699203</td>\n",
       "      <td>-0.212298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.026492</td>\n",
       "      <td>2.074186</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418155</td>\n",
       "      <td>1.597666</td>\n",
       "      <td>-2.940311</td>\n",
       "      <td>0.314922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.036666</td>\n",
       "      <td>-2.193954</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821569</td>\n",
       "      <td>-0.826074</td>\n",
       "      <td>4.530048</td>\n",
       "      <td>-0.317742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HTP       ATP  HM1_D  HM1_L  HM1_W  HM2_D  HM2_L  HM2_W  HM3_D  \\\n",
       "30 -0.558071  1.007151      0      1      0      1      0      0      0   \n",
       "31 -0.558071  2.074186      1      0      0      0      0      1      0   \n",
       "32 -2.152808 -1.660437      0      1      0      1      0      0      0   \n",
       "33 -0.026492  2.074186      1      0      0      1      0      0      0   \n",
       "34  1.036666 -2.193954      0      0      1      1      0      0      0   \n",
       "\n",
       "    HM3_L    ...     AM2_D  AM2_L  AM2_W  AM3_D  AM3_L  AM3_W      HTGD  \\\n",
       "30      0    ...         1      0      0      0      0      1 -0.388674   \n",
       "31      1    ...         0      0      1      0      0      1 -0.388674   \n",
       "32      1    ...         1      0      0      0      1      0 -1.195503   \n",
       "33      0    ...         0      0      1      0      0      1  0.418155   \n",
       "34      0    ...         1      0      0      0      1      0  0.821569   \n",
       "\n",
       "        ATGD  DiffFormPts    DiffLP  \n",
       "30  1.193709    -2.193275  0.525810  \n",
       "31  1.597666    -3.687346  0.314922  \n",
       "32 -0.422117    -0.699203 -0.212298  \n",
       "33  1.597666    -2.940311  0.314922  \n",
       "34 -0.826074     4.530048 -0.317742  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the feature information by printing the first five rows\n",
    "print( \"\\nFeature values:\" )\n",
    "display(X_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start) )\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    \n",
    "    end = time.time()\n",
    "    # Print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start) )\n",
    "    \n",
    "    return f1_score(target, y_pred, pos_label='H'), sum(target == y_pred) / float(len(y_pred))\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)) )\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print(f1, acc)\n",
    "    print(\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    \n",
    "    f1, acc = predict_labels(clf, X_test, y_test)\n",
    "    print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Tuning the parameters of XGBoost.\n",
    "def train_classifier(x):\n",
    "    #print('.')\n",
    "    normalization_coefficients = np.array([1, 100, 10, 10, 1, 1, 1, 10, 1e-3, 10])\n",
    "    \n",
    "    pars = np.array(x)*normalization_coefficients\n",
    "    # [0.1m 40, 3, 3, 0.4, 0.8, 0.8, 1, 1e-5, 2, 5]\n",
    "    parameters = { 'learning_rate' : [pars[0]],\n",
    "                   'n_estimators' : [int(pars[1])],\n",
    "                   'max_depth': [int(pars[2])],\n",
    "                   'min_child_weight': [int(pars[3])],\n",
    "                   'gamma':[pars[4]],\n",
    "                   'subsample' : [pars[5]],\n",
    "                   'colsample_bytree' : [pars[6]],\n",
    "                   'scale_pos_weight' : [pars[7]],\n",
    "                   'reg_alpha':[pars[8]]\n",
    "                 }  \n",
    "    \n",
    "    clf = xgb.XGBClassifier(random_state=int(pars[9]))\n",
    "    \n",
    "    f1_scorer = make_scorer(f1_score,pos_label='H')\n",
    "    \n",
    "    grid_obj = GridSearchCV(clf,\n",
    "                            scoring=f1_scorer,\n",
    "                            param_grid=parameters,\n",
    "                            cv=5)\n",
    "    \n",
    "    grid_obj = grid_obj.fit(X_train,y_train)\n",
    "    \n",
    "    \n",
    "    # Get the estimator\n",
    "    clf = grid_obj.best_estimator_\n",
    "    #print(clf)\n",
    "    \n",
    "    y_pred = clf.predict(X_train)    \n",
    "    f1_train = f1_score(y_train, y_pred, pos_label='H')\n",
    "    \n",
    "    y_pred = clf.predict(X_test)    \n",
    "    f1_test = f1_score(y_test, y_pred, pos_label='H')\n",
    "    \n",
    "    return f1_test, f1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: select the portion of matches to be predicted (the X_test dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.57311089303238461, 0.57311089303238461)\n"
     ]
    }
   ],
   "source": [
    "#X_all = X_all.iloc[:-N_MATCHES_TO_PREDICT, :]\n",
    "#y_all = y_all[:-N_MATCHES_TO_PREDICT]\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# Shuffle and split the dataset into training and testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "                                                    test_size = int(X_all.shape[0]*0.3),\n",
    "                                                    random_state = 2,\n",
    "                                                    stratify = y_all)\n",
    "\n",
    "# test\n",
    "print(train_classifier([0.1, 0.4, 0.3, 0.3, 0.4, 0.8, 0.8, 0.1, 1e-1, 0.2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Calibrate the classifier with a genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, numpy, multiprocessing, time\n",
    "from deap import base, creator, tools, algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tune classifier with a neural network\n",
    "import random, multiprocessing, time\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# decorators function for mutation and cross-over\n",
    "def checkBounds(min, max):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kargs):\n",
    "            offspring = func(*args, **kargs)\n",
    "            for child in offspring:\n",
    "                for i in range(len(child)): #xrange(len(child)):\n",
    "                    if child[i] > max:\n",
    "                        child[i] = max\n",
    "                    elif child[i] < min:\n",
    "                        child[i] = min\n",
    "            return offspring\n",
    "        return wrapper\n",
    "    return decorator   \n",
    "\n",
    "IND_SIZE = 10\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(1,1))#, weights=(0.001,10.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", random.random)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n=IND_SIZE)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "   \n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", train_classifier)\n",
    "\n",
    "toolbox.decorate(\"mate\", checkBounds(0.001, 1))\n",
    "toolbox.decorate(\"mutate\", checkBounds(0.001, 1))\n",
    "\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "random.seed(64)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Process Pool of 4 workers\n",
    "#pool = multiprocessing.Pool(processes=4)\n",
    "#toolbox.register(\"map\", pool.map)\n",
    "if OPTIMIZE_HYPERPARAMETERS:\n",
    "    n_individuals = 300\n",
    "    n_populations = 20\n",
    "    pop = toolbox.population(n=n_individuals)\n",
    "    hof = tools.HallOfFame(n_populations)\n",
    "\n",
    "\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "\n",
    "    print(\"Started training\")\n",
    "    best_pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=n_populations, \n",
    "                        stats=stats, halloffame=hof)\n",
    "\n",
    "    #pool.close()\n",
    "\n",
    "    print(\"Optimization done in\", time.time()-t_start, \"secs\")\n",
    "    \n",
    "    x_opt = hof[0]\n",
    "    print(\"Best individual is: %s\\nwith fitness: %s\" % (x_opt, x_opt.fitness))\n",
    "    #print(\"Achieved F1 and accurancy: \", F1_opt, acc_opt)\n",
    "\n",
    "    #joblib.dump(grid_obj.best_estimator_, 'classifier.pkl', compress = 1)\n",
    "    \n",
    "else:\n",
    "    x_opt =[0.16522059386019639, 0.18042810465105164, 0.21747378231676628,\n",
    "            0.001, 0.001, 0.798235085877988, 0.8056227427895258,\n",
    "            0.05325104138807635, 0.04135659238531564, 0.8188444724189075]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if OPTIMIZE_HYPERPARAMETERS:\n",
    "    gen, avg, min_, max_ = logbook.select(\"gen\", \"avg\", \"min\", \"max\")\n",
    "    plt.grid(True)\n",
    "    plt.plot(gen, avg, label=\"average\")\n",
    "    plt.plot(gen, min_, label=\"minimum\")\n",
    "    plt.plot(gen, max_, label=\"maximum\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Train the classifier with the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification run with optimized hyperparameters\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.80562274278952584, gamma=0.001,\n",
      "       learning_rate=0.16522059386019639, max_delta_step=0, max_depth=2,\n",
      "       min_child_weight=0, missing=None, n_estimators=18, n_jobs=1,\n",
      "       nthread=None, objective='binary:logistic', random_state=8,\n",
      "       reg_alpha=4.1356592385315641e-05, reg_lambda=1,\n",
      "       scale_pos_weight=0.53251041388076348, seed=None, silent=True,\n",
      "       subsample=0.79823508587798797)\n",
      "Made predictions in 0.0073 seconds.\n",
      "F1 score and accuracy score for training set: 0.6694 , 0.5804.\n",
      "Made predictions in 0.0026 seconds.\n",
      "F1 score and accuracy score for test set: 1.0000 , 1.0000.\n"
     ]
    }
   ],
   "source": [
    "# Shuffle and split the dataset into training and testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "                                                    test_size = 2,\n",
    "                                                    random_state = 2,\n",
    "                                                    stratify = y_all)\n",
    "\n",
    "print(\"Classification run with optimized hyperparameters\")\n",
    "\n",
    "normalization_coefficients = np.array([1, 100, 10, 10, 1, 1, 1, 10, 1e-3, 10])\n",
    "    \n",
    "pars = np.array(x_opt)*normalization_coefficients\n",
    "\n",
    "parameters = {  'learning_rate' : [pars[0]],\n",
    "                'n_estimators' : [int(pars[1])],\n",
    "                'max_depth': [int(pars[2])],\n",
    "                'min_child_weight': [int(pars[3])],\n",
    "                'gamma':[pars[4]],\n",
    "                'subsample' : [pars[5]],\n",
    "                'colsample_bytree' : [pars[6]],\n",
    "                'scale_pos_weight' : [pars[7]],\n",
    "                'reg_alpha':[pars[8]]\n",
    "            }\n",
    "\n",
    "###### THIS IS TEMPORARI ########\n",
    "parameters = { 'learning_rate' : [0.03],'n_estimators' : [20],'max_depth': [5],'min_child_weight': [5],'gamma':[0.2],\n",
    "        'subsample':[0.8],'colsample_bytree':[0.8],'scale_pos_weight' : [1],'reg_alpha':[1e-2]}\n",
    "#################################\n",
    "\n",
    "clf = xgb.XGBClassifier(random_state=int(pars[9]))\n",
    "\n",
    "f1_scorer = make_scorer(f1_score,pos_label='H')\n",
    "\n",
    "grid_obj = GridSearchCV(clf,scoring=f1_scorer,param_grid=parameters,cv=5)\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "clf = grid_obj.best_estimator_\n",
    "print(clf)\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "f1, acc = predict_labels(clf, X_train, y_train)\n",
    "print(\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    \n",
    "f1, acc = predict_labels(clf, X_test, y_test)\n",
    "print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['football_classifier_serieA_bis.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.externals import joblib\n",
    "joblib.dump(clf, out_classifierFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the confusion matrix: only the diagonal elements should be coloured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    title = 'Confusion matrix, without normalization'\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title = \"Normalized confusion matrix\"\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVIAAAEmCAYAAAAwZhg4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEv1/PkhQTQyJTiYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a195d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Home', 'NotHome'], normalize=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
